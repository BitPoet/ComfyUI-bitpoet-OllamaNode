# ComfyUI-bitpoet-OllamaNode

A very simple ComfyUI node for sending a text prompt to Ollama's chat completion API and receiving a textual answer.

## Node Settings

__model__

The model to use as shown in Ollama, e.g. "gemma3:4b".

__use_cloud__

If this toggle is active, you can use cloud models with Ollama. Make sure you have signed in before that,
and adapt your ComfyUI startup script and set OLLAMA_API_KEY to the key you created in your account.

__That's it__
